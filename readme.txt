# Generación de Casos de Prueba con IA para Pruebas Unitarias

En el ámbito del desarrollo de software, la calidad de las pruebas unitarias desempeña un papel fundamental en la garantía de la funcionalidad y robustez del código. Con la creciente presencia de tecnologías como los Large Language Models (LLM), se abre un nuevo horizonte en la generación de casos de prueba automatizados.

Este proyecto se centra en la exploración y evaluación de la capacidad de las IA generativas para crear casos de prueba para componentes de software, utilizando técnicas como particiones equivalentes y valores de borde como guías para una cobertura exhaustiva. Se compararán las estrategias manuales tradicionales con las generadas por ChatGPT (IA elegida para realizar este estudio), identificando sus diferencias, fortalezas y debilidades.

## Objetivo

El objetivo de este estudio es proporcionar una visión crítica y práctica sobre el uso de IA en el proceso de prueba de software, contribuyendo así a la comprensión de su potencial y limitaciones en este ámbito.

## Metodología

Se ha seleccionado un ejercicio representativo del curso de Programación Orientada a Objetos 1 (OO1) para llevar a cabo este estudio comparativo. El ejercicio elegido aborda una problemática compleja que involucra múltiples clases y métodos, lo que lo convierte en un caso ideal para analizar la efectividad de las pruebas unitarias generadas tanto de manera manual como mediante IA.

## Implementación

En este repositorio, se proporciona el enunciado detallado del ejercicio seleccionado, junto con su implementación correspondiente. Se invita a los interesados a explorar y contribuir al proyecto para avanzar en la comprensión de la aplicación de IA en el proceso de prueba de software.